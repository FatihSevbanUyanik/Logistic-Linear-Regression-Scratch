{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression From Scratch</h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "def importOrRenewDataset():\n",
    "    # importing dataset\n",
    "    pdTestFeatures  = pd.read_csv( os.path.join(cwd, \"data\", \"test-features.csv\"),  header=None)\n",
    "    pdTestLabels    = pd.read_csv( os.path.join(cwd, \"data\", \"test-labels.csv\"),    header=None)\n",
    "    pdTrainFeatures = pd.read_csv( os.path.join(cwd, \"data\", \"train-features.csv\"), header=None)\n",
    "    pdTrainLabels   = pd.read_csv( os.path.join(cwd, \"data\", \"train-labels.csv\"),   header=None)\n",
    "    \n",
    "    # labeling as 0 or 1 the dataset\n",
    "    pdTestLabels[ pdTestLabels[0] <  90 ] = 0\n",
    "    pdTestLabels[ pdTestLabels[0] >= 90 ] = 1\n",
    "    pdTrainLabels[ pdTrainLabels[0] <  90 ] = 0\n",
    "    pdTrainLabels[ pdTrainLabels[0] >= 90 ] = 1\n",
    "    \n",
    "    # dataset \n",
    "    npTestFeatures  = pdTestFeatures.values\n",
    "    npTestLabels    = pdTestLabels.values\n",
    "    npTrainFeatures = pdTrainFeatures.values\n",
    "    npTrainLabels   = pdTrainLabels.values\n",
    "    \n",
    "    # properties\n",
    "    testSampleCount  = npTestFeatures.shape[0]\n",
    "    trainSampleCount = npTrainFeatures.shape[0]\n",
    "    featureCount = npTestFeatures.shape[1]\n",
    "    weights = np.zeros((8, 1))\n",
    "    bias = 0\n",
    "    \n",
    "    return bias, weights, npTrainFeatures, npTrainLabels, npTestFeatures,\\\n",
    "           npTestLabels, testSampleCount, trainSampleCount, featureCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sigmoidFunction(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# updating weights \n",
    "def calculateDerivatives(npTrainFeatures, npTrainLabels, trainSampleCount, bias, weights):\n",
    "    z = npTrainFeatures.dot(weights) + bias\n",
    "    npTrainLabelsHead = sigmoidFunction(z)\n",
    "    # finding out derivatives\n",
    "    derivativeOfWeight = np.dot(npTrainFeatures.T , (npTrainLabels - npTrainLabelsHead)) / trainSampleCount \n",
    "    derivativeOfBias   = np.sum(npTrainLabels - npTrainLabelsHead) / trainSampleCount\n",
    "    return  derivativeOfWeight, derivativeOfBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTestResults(weights, bias, npTestFeatures, npTestLabels, testSampleCount):\n",
    "    z = npTestFeatures.dot(weights) + bias\n",
    "    npTestLabelsHead = sigmoidFunction(z)\n",
    "    predictions = np.zeros((testSampleCount, 1))\n",
    "\n",
    "    for i in range(testSampleCount):\n",
    "        if npTestLabelsHead[i,0] > 0.5:\n",
    "            predictions[i,0] = 1\n",
    "        else:\n",
    "            predictions[i,0] = 0\n",
    "    \n",
    "    # calculating confusion matrix\n",
    "    truePositives  = np.sum( np.logical_and( npTestLabels, predictions) )\n",
    "    falsePositives = np.sum( np.logical_and( np.logical_not(npTestLabels), predictions) ) \n",
    "    falseNegatives = np.sum( np.logical_and( npTestLabels, np.logical_not(predictions)) ) \n",
    "    trueNegatives  = np.sum( np.logical_and( np.logical_not(npTestLabels), np.logical_not(predictions)) )\n",
    "\n",
    "    # printing out confusion matrix\n",
    "    print(\"Learning rate \" + str(learningRate) + \": \")\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    print(\"True Positives: \"  + str(truePositives))\n",
    "    print(\"False Positives: \" + str(falsePositives))\n",
    "    print(\"False Negatives: \" + str(falseNegatives))\n",
    "    print(\"True Negatives: \" + str(trueNegatives))\n",
    "    \n",
    "    # adding one to avoid nan values\n",
    "    truePositives  = truePositives  + 1\n",
    "    falsePositives = falsePositives + 1\n",
    "    falseNegatives = falseNegatives + 1\n",
    "    trueNegatives  = trueNegatives  + 1\n",
    "    testSampleCount += 4\n",
    "    \n",
    "    acurracy = ((truePositives + trueNegatives) / testSampleCount) * 100\n",
    "    precision = truePositives / (truePositives + falsePositives) \n",
    "    recall = truePositives / (truePositives + falseNegatives)\n",
    "    negativePredictiveValue = trueNegatives / (falseNegatives + trueNegatives)\n",
    "    falsePositiveRate = falsePositives / (falsePositives + trueNegatives)\n",
    "    falseDiscoveryRate = falsePositives / (falsePositives + truePositives)\n",
    "    f1Score = (2 * precision * recall) / (precision + recall)\n",
    "    f2Score = (5 * precision * recall) / (4 * precision + recall)\n",
    "    \n",
    "    # printing out results\n",
    "    print(\"Acurracy: \" + str(acurracy))\n",
    "    print(\"Precision: \" + str(precision))\n",
    "    print(\"Recall: \" + str(recall))\n",
    "    print(\"Negative Predictive Value: \" + str(negativePredictiveValue))\n",
    "    print(\"False Positive Rate: \" + str(falsePositiveRate))\n",
    "    print(\"False Discovery Rate: \" + str(falseDiscoveryRate))\n",
    "    print(\"F1 Score: \" + str(f1Score))\n",
    "    print(\"F2 Score: \" + str(f2Score))\n",
    "    print()\n",
    "    \n",
    "    return truePositives, falsePositives, falseNegatives, trueNegatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMicroMacroResults(truePositiveArr, falsePositiveArr, falseNegativeArr, trueNegativeArr):\n",
    "    precision = truePositiveArr / (truePositiveArr + falsePositiveArr)\n",
    "    recall = truePositiveArr / (truePositiveArr + falseNegativeArr)\n",
    "    \n",
    "    # MACRO AVERAGING\n",
    "    macroPrecision = precision.mean() \n",
    "    macroRecall = recall.mean()\n",
    "    macroNegativePredictiveValue = (trueNegativeArr / (falseNegativeArr + trueNegativeArr)).mean()\n",
    "    macroFalsePositiveRate = (falsePositiveArr / (falsePositiveArr + trueNegativeArr)).mean()\n",
    "    macroFalseDiscoveryRate = (falsePositiveArr / (falsePositiveArr + truePositiveArr)).mean()\n",
    "    macroF1Score = ((2 * precision * recall) / (precision + recall)).mean()\n",
    "    macroF2Score = ((5 * precision * recall) / (4 * precision + recall)).mean()\n",
    "    \n",
    "    # MICRO AVERAGING\n",
    "    microPrecision = truePositiveArr.sum() / ((truePositiveArr + falsePositiveArr).sum())\n",
    "    microRecall = truePositiveArr.sum() / ((truePositiveArr + falseNegativeArr).sum())\n",
    "    microNegativePredictiveValue = trueNegatives.sum() / ((falseNegatives + trueNegatives).sum())\n",
    "    microFalsePositiveRate = falsePositives.sum() / ((falsePositives + trueNegatives).sum())\n",
    "    microFalseDiscoveryRate = falsePositives.sum() / ((falsePositives + truePositives).sum())\n",
    "    microF1Score = (2 * precision * recall).sum() / ((precision + recall).sum())\n",
    "    microF2Score = (5 * precision * recall).sum() / ((4 * precision + recall).sum())\n",
    "    \n",
    "    # printing results\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('-------------------------MACRO AVERAGING-------------------------')\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(\"Macro Precision: \" + str(macroPrecision))\n",
    "    print(\"Macro Recall: \" + str(macroRecall))\n",
    "    print(\"Macro Negative Predictive Value: \" + str(macroNegativePredictiveValue))\n",
    "    print(\"Macro False Positive Rate: \" + str(macroFalsePositiveRate))\n",
    "    print(\"Macro False Discovery Rate: \" + str(macroFalseDiscoveryRate))\n",
    "    print(\"Macro F1 Score: \" + str(macroF1Score))\n",
    "    print(\"Macro F2 Score: \" + str(macroF2Score))\n",
    "    print()\n",
    "    \n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('-------------------------MICRO AVERAGING-------------------------')\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(\"Micro Precision: \" + str(microPrecision))\n",
    "    print(\"Micro Recall: \" + str(microRecall))\n",
    "    print(\"Micro Negative Predictive Value: \" + str(microNegativePredictiveValue))\n",
    "    print(\"Micro False Positive Rate: \" + str(microFalsePositiveRate))\n",
    "    print(\"Micro False Discovery Rate: \" + str(microFalseDiscoveryRate))\n",
    "    print(\"Micro F1 Score: \" + str(microF1Score))\n",
    "    print(\"Micro F2 Score: \" + str(microF2Score))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Question 3.1: </strong>You will implement full batch gradient ascent algorithm to train your logistic\n",
    "regression model. Initialize all weights to 0. Try different learning rates from the given logarithmic scale\n",
    "[10􀀀5; 10􀀀4; 10􀀀3; 10􀀀2; 10􀀀1] and choose the one which works best for you. Use 1000 iterations to train your\n",
    "model. Report the accuracy and the confusion matrix using your model on the test set given. Calculate\n",
    "and report micro and macro averages of precision, recall, negative predictive value (NPV), false positive rate\n",
    "(FPR), false discovery rate (FDR), F1 and F2 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate 1e-05: \n",
      "-----------------------------------------------------\n",
      "True Positives: 2342\n",
      "False Positives: 1036\n",
      "False Negatives: 0\n",
      "True Negatives: 0\n",
      "Acurracy: 69.30810171496155\n",
      "Precision: 0.6931952662721893\n",
      "Recall: 0.9995733788395904\n",
      "Negative Predictive Value: 0.5\n",
      "False Positive Rate: 0.9990366088631984\n",
      "False Discovery Rate: 0.30680473372781064\n",
      "F1 Score: 0.8186582809224318\n",
      "F2 Score: 0.9183913452492946\n",
      "\n",
      "Learning rate 0.0001: \n",
      "-----------------------------------------------------\n",
      "True Positives: 2289\n",
      "False Positives: 868\n",
      "False Negatives: 53\n",
      "True Negatives: 168\n",
      "Acurracy: 72.70845653459492\n",
      "Precision: 0.7249129471351694\n",
      "Recall: 0.976962457337884\n",
      "Negative Predictive Value: 0.757847533632287\n",
      "False Positive Rate: 0.8371868978805395\n",
      "False Discovery Rate: 0.27508705286483065\n",
      "F1 Score: 0.8322733054697438\n",
      "F2 Score: 0.9134423613881133\n",
      "\n",
      "Learning rate 0.001: \n",
      "-----------------------------------------------------\n",
      "True Positives: 2105\n",
      "False Positives: 247\n",
      "False Negatives: 237\n",
      "True Negatives: 789\n",
      "Acurracy: 85.62980484920165\n",
      "Precision: 0.8946474086661003\n",
      "Recall: 0.8984641638225256\n",
      "Negative Predictive Value: 0.7684824902723736\n",
      "False Positive Rate: 0.23892100192678228\n",
      "False Discovery Rate: 0.10535259133389975\n",
      "F1 Score: 0.8965517241379309\n",
      "F2 Score: 0.89769820971867\n",
      "\n",
      "Learning rate 0.01: \n",
      "-----------------------------------------------------\n",
      "True Positives: 2126\n",
      "False Positives: 266\n",
      "False Negatives: 216\n",
      "True Negatives: 770\n",
      "Acurracy: 85.6889414547605\n",
      "Precision: 0.8884711779448622\n",
      "Recall: 0.9074232081911263\n",
      "Negative Predictive Value: 0.7803643724696356\n",
      "False Positive Rate: 0.25722543352601157\n",
      "False Discovery Rate: 0.11152882205513784\n",
      "F1 Score: 0.8978471929084002\n",
      "F2 Score: 0.9035683942225999\n",
      "\n",
      "Learning rate 0.1: \n",
      "-----------------------------------------------------\n",
      "True Positives: 1394\n",
      "False Positives: 94\n",
      "False Negatives: 948\n",
      "True Negatives: 942\n",
      "Acurracy: 69.13069189828504\n",
      "Precision: 0.9362416107382551\n",
      "Recall: 0.5951365187713311\n",
      "Negative Predictive Value: 0.49841437632135305\n",
      "False Positive Rate: 0.09152215799614644\n",
      "False Discovery Rate: 0.06375838926174497\n",
      "F1 Score: 0.727699530516432\n",
      "F2 Score: 0.6419105466593042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learningRates = [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "# APPLYING FULL BATCH GRADIENT DESCENT\n",
    "batchGradientTruePositives  = []\n",
    "batchGradientFalsePositives = []\n",
    "batchGradientFalseNegatives = []\n",
    "batchGradientTrueNegatives  = []\n",
    "\n",
    "for learningRate in learningRates:\n",
    "    bias, weights, npTrainFeatures, npTrainLabels, npTestFeatures, npTestLabels,\\\n",
    "    testSampleCount, trainSampleCount, featureCount = importOrRenewDataset()\n",
    "    \n",
    "    for j in range(1000):  \n",
    "        derivativeOfWeight, derivativeOfBias = calculateDerivatives\\\n",
    "        (npTrainFeatures, npTrainLabels, trainSampleCount, bias, weights)\n",
    "    \n",
    "        # updating weights and bias\n",
    "        weights = weights + learningRate * derivativeOfWeight\n",
    "        bias = bias + learningRate * derivativeOfBias\n",
    "        \n",
    "    truePositives, falsePositives, falseNegatives, trueNegatives = \\\n",
    "    printTestResults(weights, bias, npTestFeatures, npTestLabels, testSampleCount)\n",
    "    \n",
    "    batchGradientTruePositives.append( truePositives )\n",
    "    batchGradientFalsePositives.append( falsePositives )\n",
    "    batchGradientFalseNegatives.append( falseNegatives )\n",
    "    batchGradientTrueNegatives.append( trueNegatives )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "-------------------------MACRO AVERAGING-------------------------\n",
      "-----------------------------------------------------------------\n",
      "Macro Precision: 0.8274936821513152\n",
      "Macro Recall: 0.8755119453924914\n",
      "Macro Negative Predictive Value: 0.6610217545391299\n",
      "Macro False Positive Rate: 0.4847784200385356\n",
      "Macro False Discovery Rate: 0.17250631784868475\n",
      "Macro F1 Score: 0.8346060067909878\n",
      "Macro F2 Score: 0.8550021714475964\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "-------------------------MICRO AVERAGING-------------------------\n",
      "-----------------------------------------------------------------\n",
      "Micro Precision: 0.803083665962276\n",
      "Micro Recall: 0.8755119453924914\n",
      "Micro Negative Predictive Value: 0.49841437632135305\n",
      "Micro False Positive Rate: 0.09152215799614644\n",
      "Micro False Discovery Rate: 0.06375838926174497\n",
      "Micro F1 Score: 0.8381256729966073\n",
      "Micro F2 Score: 0.8525488484824458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing out micro and macro results.\n",
    "batchGradientTruePositives  = np.array(batchGradientTruePositives)\n",
    "batchGradientFalsePositives = np.array(batchGradientFalsePositives)\n",
    "batchGradientFalseNegatives = np.array(batchGradientFalseNegatives)\n",
    "batchGradientTrueNegatives  = np.array(batchGradientTrueNegatives)\n",
    "\n",
    "printMicroMacroResults( batchGradientTruePositives, batchGradientFalsePositives, \\\n",
    "                       batchGradientFalseNegatives, batchGradientTrueNegatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Question 3.2: </strong> You are NOT allowed to use any machine learning libraries to train and test your model for this question. You will implement mini-batch gradient ascent algorithm with batch size = 32 and stochastic gradient ascent algorithm to train your logistic regression model. Initialize all weights to 0. Use the learning rate you have chosen in Question 3.1 and perform 1000 iterations to train your model. Report the accuracies and the confusion matrices using your models on the given test set. Calculate and report micro and macro averages of precision, recall, negative predictive value (NPV), false positive rate (FPR), false discovery rate (FDR), F1 and F2 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate 1e-05: \n",
      "-----------------------------------------------------\n",
      "True Positives: 1616\n",
      "False Positives: 209\n",
      "False Negatives: 726\n",
      "True Negatives: 827\n",
      "Acurracy: 72.29450029568302\n",
      "Precision: 0.8850574712643678\n",
      "Recall: 0.6898464163822525\n",
      "Negative Predictive Value: 0.532475884244373\n",
      "False Positive Rate: 0.2023121387283237\n",
      "False Discovery Rate: 0.11494252873563218\n",
      "F1 Score: 0.7753536322224885\n",
      "F2 Score: 0.7216816924038204\n",
      "\n",
      "Learning rate 0.0001: \n",
      "-----------------------------------------------------\n",
      "True Positives: 1426\n",
      "False Positives: 204\n",
      "False Negatives: 916\n",
      "True Negatives: 832\n",
      "Acurracy: 66.82436428149025\n",
      "Precision: 0.8743872549019608\n",
      "Recall: 0.6087883959044369\n",
      "Negative Predictive Value: 0.476\n",
      "False Positive Rate: 0.197495183044316\n",
      "False Discovery Rate: 0.1256127450980392\n",
      "F1 Score: 0.7178068410462777\n",
      "F2 Score: 0.6481649709302325\n",
      "\n",
      "Learning rate 0.001: \n",
      "-----------------------------------------------------\n",
      "True Positives: 1619\n",
      "False Positives: 338\n",
      "False Negatives: 723\n",
      "True Negatives: 698\n",
      "Acurracy: 68.56889414547605\n",
      "Precision: 0.8269525267993875\n",
      "Recall: 0.6911262798634812\n",
      "Negative Predictive Value: 0.49121574139142654\n",
      "False Positive Rate: 0.3265895953757225\n",
      "False Discovery Rate: 0.17304747320061256\n",
      "F1 Score: 0.7529630490355567\n",
      "F2 Score: 0.7146007940008822\n",
      "\n",
      "Learning rate 0.01: \n",
      "-----------------------------------------------------\n",
      "True Positives: 2340\n",
      "False Positives: 1030\n",
      "False Negatives: 2\n",
      "True Negatives: 6\n",
      "Acurracy: 69.42637492607925\n",
      "Precision: 0.6942467378410438\n",
      "Recall: 0.9987201365187713\n",
      "Negative Predictive Value: 0.7\n",
      "False Positive Rate: 0.9932562620423893\n",
      "False Discovery Rate: 0.3057532621589561\n",
      "F1 Score: 0.8191042687193841\n",
      "F2 Score: 0.9181832444304989\n",
      "\n",
      "Learning rate 0.1: \n",
      "-----------------------------------------------------\n",
      "True Positives: 2325\n",
      "False Positives: 1034\n",
      "False Negatives: 17\n",
      "True Negatives: 2\n",
      "Acurracy: 68.86457717327026\n",
      "Precision: 0.6920559357334126\n",
      "Recall: 0.992320819112628\n",
      "Negative Predictive Value: 0.14285714285714285\n",
      "False Positive Rate: 0.9971098265895953\n",
      "False Discovery Rate: 0.3079440642665873\n",
      "F1 Score: 0.8154250657318142\n",
      "F2 Score: 0.9130878542827982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# APPLYING MINI BATCH GRADIENT DESCENT WITH SIZE = 32\n",
    "miniBatchGradientTruePositives  = []\n",
    "miniBatchGradientFalsePositives = []\n",
    "miniBatchGradientFalseNegatives = []\n",
    "miniBatchGradientTrueNegatives  = []\n",
    "\n",
    "\n",
    "for learningRate in learningRates:\n",
    "    bias, weights, npTrainFeatures, npTrainLabels, npTestFeatures, npTestLabels,\\\n",
    "    testSampleCount, trainSampleCount, featureCount = importOrRenewDataset()\n",
    "    \n",
    "    for j in range(1000):  \n",
    "        idx = np.random.randint(testSampleCount, size=32)\n",
    "        npTrainLabels32 = npTrainLabels[idx]\n",
    "        npTrainFeatures32 = npTrainFeatures[idx,:]\n",
    "        trainSampleCount32 = 32\n",
    "        \n",
    "        derivativeOfWeight, derivativeOfBias = calculateDerivatives\\\n",
    "        (npTrainFeatures32, npTrainLabels32, trainSampleCount32, bias, weights)\n",
    "    \n",
    "        # updating weights and bias\n",
    "        weights = weights + learningRate * derivativeOfWeight\n",
    "        bias = bias + learningRate * derivativeOfBias\n",
    "        \n",
    "    truePositives, falsePositives, falseNegatives, trueNegatives = \\\n",
    "    printTestResults(weights, bias, npTestFeatures, npTestLabels, testSampleCount)\n",
    "    \n",
    "    miniBatchGradientTruePositives.append( truePositives )\n",
    "    miniBatchGradientFalsePositives.append( falsePositives )\n",
    "    miniBatchGradientFalseNegatives.append( falseNegatives )\n",
    "    miniBatchGradientTrueNegatives.append( trueNegatives )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "-------------------------MACRO AVERAGING-------------------------\n",
      "-----------------------------------------------------------------\n",
      "Macro Precision: 0.7945399853080346\n",
      "Macro Recall: 0.796160409556314\n",
      "Macro Negative Predictive Value: 0.4685097536985885\n",
      "Macro False Positive Rate: 0.5433526011560693\n",
      "Macro False Discovery Rate: 0.20546001469196548\n",
      "Macro F1 Score: 0.7761305713511042\n",
      "Macro F2 Score: 0.7831437112096464\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "-------------------------MICRO AVERAGING-------------------------\n",
      "-----------------------------------------------------------------\n",
      "Micro Precision: 0.7679203357748333\n",
      "Micro Recall: 0.796160409556314\n",
      "Micro Negative Predictive Value: 0.14285714285714285\n",
      "Micro False Positive Rate: 0.9971098265895953\n",
      "Micro False Discovery Rate: 0.3079440642665873\n",
      "Micro F1 Score: 0.7781475084634338\n",
      "Micro F2 Score: 0.7786234121325488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing out micro and macro results.\n",
    "miniBatchGradientTruePositives  = np.array(miniBatchGradientTruePositives)\n",
    "miniBatchGradientFalsePositives = np.array(miniBatchGradientFalsePositives)\n",
    "miniBatchGradientFalseNegatives = np.array(miniBatchGradientFalseNegatives)\n",
    "miniBatchGradientTrueNegatives  = np.array(miniBatchGradientTrueNegatives)\n",
    "\n",
    "printMicroMacroResults( miniBatchGradientTruePositives, miniBatchGradientFalsePositives, \\\n",
    "                       miniBatchGradientFalseNegatives, miniBatchGradientTrueNegatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate 1e-05: \n",
      "-----------------------------------------------------\n",
      "True Positives: 2342\n",
      "False Positives: 1036\n",
      "False Negatives: 0\n",
      "True Negatives: 0\n",
      "Acurracy: 69.30810171496155\n",
      "Precision: 0.6931952662721893\n",
      "Recall: 0.9995733788395904\n",
      "Negative Predictive Value: 0.5\n",
      "False Positive Rate: 0.9990366088631984\n",
      "False Discovery Rate: 0.30680473372781064\n",
      "F1 Score: 0.8186582809224318\n",
      "F2 Score: 0.9183913452492946\n",
      "\n",
      "Learning rate 0.0001: \n",
      "-----------------------------------------------------\n",
      "True Positives: 2342\n",
      "False Positives: 1036\n",
      "False Negatives: 0\n",
      "True Negatives: 0\n",
      "Acurracy: 69.30810171496155\n",
      "Precision: 0.6931952662721893\n",
      "Recall: 0.9995733788395904\n",
      "Negative Predictive Value: 0.5\n",
      "False Positive Rate: 0.9990366088631984\n",
      "False Discovery Rate: 0.30680473372781064\n",
      "F1 Score: 0.8186582809224318\n",
      "F2 Score: 0.9183913452492946\n",
      "\n",
      "Learning rate 0.001: \n",
      "-----------------------------------------------------\n",
      "True Positives: 2342\n",
      "False Positives: 1036\n",
      "False Negatives: 0\n",
      "True Negatives: 0\n",
      "Acurracy: 69.30810171496155\n",
      "Precision: 0.6931952662721893\n",
      "Recall: 0.9995733788395904\n",
      "Negative Predictive Value: 0.5\n",
      "False Positive Rate: 0.9990366088631984\n",
      "False Discovery Rate: 0.30680473372781064\n",
      "F1 Score: 0.8186582809224318\n",
      "F2 Score: 0.9183913452492946\n",
      "\n",
      "Learning rate 0.01: \n",
      "-----------------------------------------------------\n",
      "True Positives: 2342\n",
      "False Positives: 1036\n",
      "False Negatives: 0\n",
      "True Negatives: 0\n",
      "Acurracy: 69.30810171496155\n",
      "Precision: 0.6931952662721893\n",
      "Recall: 0.9995733788395904\n",
      "Negative Predictive Value: 0.5\n",
      "False Positive Rate: 0.9990366088631984\n",
      "False Discovery Rate: 0.30680473372781064\n",
      "F1 Score: 0.8186582809224318\n",
      "F2 Score: 0.9183913452492946\n",
      "\n",
      "Learning rate 0.1: \n",
      "-----------------------------------------------------\n",
      "True Positives: 2342\n",
      "False Positives: 1036\n",
      "False Negatives: 0\n",
      "True Negatives: 0\n",
      "Acurracy: 69.30810171496155\n",
      "Precision: 0.6931952662721893\n",
      "Recall: 0.9995733788395904\n",
      "Negative Predictive Value: 0.5\n",
      "False Positive Rate: 0.9990366088631984\n",
      "False Discovery Rate: 0.30680473372781064\n",
      "F1 Score: 0.8186582809224318\n",
      "F2 Score: 0.9183913452492946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# APPLYING STOCHASTIC GRADIENT DESCENT \n",
    "stochasticGradientTruePositives  = []\n",
    "stochasticGradientFalsePositives = []\n",
    "stochasticGradientFalseNegatives = []\n",
    "stochasticGradientTrueNegatives  = []\n",
    "\n",
    "for learningRate in learningRates:\n",
    "    bias, weights, npTrainFeatures, npTrainLabels, npTestFeatures, npTestLabels,\\\n",
    "    testSampleCount, trainSampleCount, featureCount = importOrRenewDataset()\n",
    "    \n",
    "    for j in range(1000):      \n",
    "        for k in range(testSampleCount):\n",
    "            idx = np.array([k])\n",
    "            npTrainLabelSample = npTrainLabels[idx]\n",
    "            npTrainFeaturesSample = npTrainFeatures[idx,:]\n",
    "            trainSampleCountSample = 1\n",
    "        \n",
    "            derivativeOfWeight, derivativeOfBias = calculateDerivatives\\\n",
    "            (npTrainFeatures32, npTrainLabels32, trainSampleCount32, bias, weights)\n",
    "    \n",
    "            # updating weights and bias\n",
    "            weights = weights + learningRate * derivativeOfWeight\n",
    "            bias = bias + learningRate * derivativeOfBias\n",
    "        \n",
    "    truePositives, falsePositives, falseNegatives, trueNegatives = \\\n",
    "    printTestResults(weights, bias, npTestFeatures, npTestLabels, testSampleCount)\n",
    "    \n",
    "    stochasticGradientTruePositives.append( truePositives )\n",
    "    stochasticGradientFalsePositives.append( falsePositives )\n",
    "    stochasticGradientFalseNegatives.append( falseNegatives )\n",
    "    stochasticGradientTrueNegatives.append( trueNegatives )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "-------------------------MACRO AVERAGING-------------------------\n",
      "-----------------------------------------------------------------\n",
      "Macro Precision: 0.6931952662721893\n",
      "Macro Recall: 0.9995733788395904\n",
      "Macro Negative Predictive Value: 0.5\n",
      "Macro False Positive Rate: 0.9990366088631986\n",
      "Macro False Discovery Rate: 0.30680473372781064\n",
      "Macro F1 Score: 0.8186582809224318\n",
      "Macro F2 Score: 0.9183913452492944\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "-------------------------MICRO AVERAGING-------------------------\n",
      "-----------------------------------------------------------------\n",
      "Micro Precision: 0.6931952662721893\n",
      "Micro Recall: 0.9995733788395904\n",
      "Micro Negative Predictive Value: 0.5\n",
      "Micro False Positive Rate: 0.9990366088631984\n",
      "Micro False Discovery Rate: 0.30680473372781064\n",
      "Micro F1 Score: 0.8186582809224318\n",
      "Micro F2 Score: 0.9183913452492946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing out micro and macro results.\n",
    "stochasticGradientTruePositives  = np.array(stochasticGradientTruePositives)\n",
    "stochasticGradientFalsePositives = np.array(stochasticGradientFalsePositives)\n",
    "stochasticGradientFalseNegatives = np.array(stochasticGradientFalseNegatives)\n",
    "stochasticGradientTrueNegatives  = np.array(stochasticGradientTrueNegatives)\n",
    "\n",
    "printMicroMacroResults( stochasticGradientTruePositives, stochasticGradientFalsePositives, \\\n",
    "                       stochasticGradientFalseNegatives, stochasticGradientTrueNegatives)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
